{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T10:15:56.488371Z",
     "start_time": "2023-04-12T10:15:52.962025Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import opensmile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(audio, sra, feat, database):\n",
    "    # CHANGE CONFIG OPTIONS\n",
    "    # path: C:\\Users\\lugoza\\AppData\\Local\\Continuum\\anaconda3\\envs\\Helios\\Lib\\site-packages\\opensmile\\core\\config\\shared\n",
    "    # file: FrameModeFunctionals.conf.inc\n",
    "    # path: C:\\Users\\lugoza\\AppData\\Local\\Continuum\\anaconda3\\envs\\Helios\\Lib\\site-packages\\opensmile\\core\\config\\egemaps\\v02\n",
    "    # features with functionals frameMode=full \n",
    "    # default (short-term): frameMode = full, frameSize = 0, frameStep = 0 \n",
    "    # mid-term: frameMode = fixed, frameSize = 5, frameStep = 3\n",
    "    # details here: https://audeering.github.io/opensmile/get-started.html (search frameModeFunctionalsConf)\n",
    "    \n",
    "    # Resample audio\n",
    "    if database == 'vosome':\n",
    "        fm = 44100\n",
    "        audio = librosa.resample(audio, sra, fm) \n",
    "    elif database == 'ravdess':\n",
    "        fm = sra\n",
    "    elif database == 'iemocap':\n",
    "        fm = sra\n",
    "    \n",
    "    # Normalize audio\n",
    "    audio = librosa.util.normalize(audio)\n",
    "    \n",
    "    # Feature extraction\n",
    "    if feat == 'long term':\n",
    "        smile = opensmile.Smile(\n",
    "            feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "            feature_level=opensmile.FeatureLevel.Functionals,\n",
    "            )\n",
    "        df_features = smile.process_signal(audio, fm)\n",
    "    \n",
    "    elif feat == 'short term':\n",
    "        smile = opensmile.Smile(\n",
    "            feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "            feature_level=opensmile.FeatureLevel.LowLevelDescriptors,\n",
    "            )\n",
    "        df_features = smile.process_signal(audio, fm)      \n",
    "        \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long-term features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMOVOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Computing long term features...\n",
      "Duration: 19.99 min\n"
     ]
    }
   ],
   "source": [
    "# path = \"F:/Proyectos/1-HELIOS/0-Estudio-emociones-voz/0-Datos/Audios/BBBDD-Estudio completo/Completo-1000\" \n",
    "path = 'data/VOSOME/audios'\n",
    "feat = 'long term'\n",
    "database = 'vosome'\n",
    "\n",
    "print('[INFO] Computing long term features...')\n",
    "tic = time.time()\n",
    "names = []\n",
    "for count, audio in enumerate(os.listdir(path)):\n",
    "    names.append(int(audio.split('.')[0]))\n",
    "    signal_audio, sra = librosa.load(path+'/'+audio, sr=None)\n",
    "    if count == 0:\n",
    "        df_features = process_audio(signal_audio, sra, feat, database)\n",
    "    else:\n",
    "        y = process_audio(signal_audio, sra, feat, database)\n",
    "        df_features = pd.concat([df_features.reset_index(drop=True),y.reset_index(drop=True)],axis=0)\n",
    "df_features.insert(0,'id',names)\n",
    "df_features.to_excel('data/VOSOME/features/eGeMAPS_functionals.xlsx',index=False)\n",
    "toc = time.time()\n",
    "print('Duration:',round((toc-tic)/60,2),'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAVDESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/RAVDESS/audios/'\n",
    "files = []\n",
    "for actor in os.listdir(data_path):\n",
    "    for audio_file in os.listdir(data_path + actor + '/'):\n",
    "        files.append(data_path + actor + '/' + audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Computing long term features...\n",
      "Duration: 3.45 min\n"
     ]
    }
   ],
   "source": [
    "path = \"data/RAVDESS/audios\" \n",
    "feat = 'long term'\n",
    "database = 'ravdess'\n",
    "\n",
    "print('[INFO] Computing long term features...')\n",
    "tic = time.time()\n",
    "names = []\n",
    "for count, audio in enumerate(files):\n",
    "    names.append(audio.split('/')[-1].split('.')[0])\n",
    "    signal_audio, sra = librosa.load(audio, sr=None)\n",
    "    if count == 0:\n",
    "        df_features = process_audio(signal_audio, sra, feat, database)\n",
    "    else:\n",
    "        y = process_audio(signal_audio, sra, feat, database)\n",
    "        df_features = pd.concat([df_features.reset_index(drop=True),y.reset_index(drop=True)],axis=0)\n",
    "df_features.insert(0,'id',names)\n",
    "df_features.to_excel('data/RAVDESS/features/eGeMAPS_functionals.xlsx',index=False)\n",
    "toc = time.time()\n",
    "print('Duration:',round((toc-tic)/60,2),'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IEMOCAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Computing long term features...\n",
      "- Session:  1\n",
      "- Session:  2\n",
      "- Session:  3\n",
      "- Session:  4\n",
      "- Session:  5\n",
      "Duration: 45.22 min\n"
     ]
    }
   ],
   "source": [
    "path = 'D:/lugoza/IEMOCAP/'\n",
    "feat = 'long term'\n",
    "database = 'iemocap'\n",
    "\n",
    "print('[INFO] Computing long term features...')\n",
    "tic = time.time()\n",
    "names = []\n",
    "count = 0\n",
    "for session in [folder for folder in os.listdir(path) if folder.startswith('Session')]:\n",
    "    print('- Session: ',session[-1])\n",
    "    for improv in os.listdir(path + session +'/sentences/wav/'):\n",
    "        for audio in [f for f in os.listdir(path + session +'/sentences/wav/'+improv+'/') if f.endswith('.wav')]:\n",
    "            path_file = path + session +'/sentences/wav/'+improv+'/'+audio    \n",
    "            names.append(audio.split('.')[0])\n",
    "            signal_audio, sra = librosa.load(path_file, sr=None)\n",
    "            if sra != 16000:\n",
    "                print(sra)\n",
    "            if count == 0:\n",
    "                df_features = process_audio(signal_audio, sra, feat, database)\n",
    "                count += 1\n",
    "            else:\n",
    "                y = process_audio(signal_audio, sra, feat, database)\n",
    "                df_features = pd.concat([df_features.reset_index(drop=True),y.reset_index(drop=True)],axis=0)\n",
    "df_features.insert(0,'id',names)\n",
    "df_features.reset_index(inplace=True, drop=True)\n",
    "df_features.to_excel('data/IEMOCAP/features/eGeMAPS_functionals.xlsx',index=False)\n",
    "toc = time.time()\n",
    "print('Duration:',round((toc-tic)/60,2),'min')            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
