{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54186d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install -r requirements_speechbrain.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d917b1bc",
   "metadata": {},
   "source": [
    "# Pre-trained models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8984dae",
   "metadata": {},
   "source": [
    "| Pre-trained model | Name in the article | URL |\n",
    "| :- | :- | :- |\n",
    "| X-vector | x-vector | https://huggingface.co/speechbrain/spkrec-xvect-voxceleb  |   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5effc8fe",
   "metadata": {},
   "source": [
    "# 1. Extract embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f56b13",
   "metadata": {},
   "source": [
    "The code used to extract embeddings is consistent across all the databases studied: EMOVOME, RAVDESS, and IEMOCAP. \n",
    "\n",
    "The only variations are due to the different file structures of each database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8024edec",
   "metadata": {},
   "source": [
    "## 1.1 EMOVOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8404850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os  # For interacting with the file system\n",
    "import time  # For measuring time intervals\n",
    "import librosa  # For audio processing\n",
    "import numpy as np  # For numerical operations\n",
    "import torch  # For tensor computations\n",
    "# import torchaudio  # For audio loading \n",
    "from speechbrain.pretrained import EncoderClassifier  # Import EncoderClassifier from SpeechBrain pretrained models\n",
    "\n",
    "# Load pretrained model\n",
    "classifier = EncoderClassifier.from_hparams(\n",
    "    source=\"speechbrain/spkrec-xvect-voxceleb\",  # Model source identifier\n",
    "    savedir=\"C:/Users/lugoza/Documents/AnacondaFiles/HELIOS_final/data/VOSOME/embeddings/speechbrain-x-vector/models/\"  # Directory containing model checkpoints\n",
    ")\n",
    "\n",
    "# Calculate embeddings per audio file\n",
    "path = 'C:/Users/lugoza/Documents/AnacondaFiles/HELIOS_final/data/VOSOME/audios'  # Path to audio files\n",
    "path_save = 'data/VOSOME/embeddings/speechbrain-x-vector/audio_embeddings/'  # Path to save embeddings\n",
    "\n",
    "tic = time.time()  # Start timing\n",
    "\n",
    "# Iterate through each audio file in the specified path\n",
    "for audio in os.listdir(path):\n",
    "    id_audio = audio.split('.')[0]  # Extract the audio file ID\n",
    "    \n",
    "    # Load audio using librosa due to potential issues with torchaudio's ogg file support\n",
    "    signal, fs = librosa.load(path+'/'+audio, sr=16000, mono=True)\n",
    "    \n",
    "    # Convert the audio waveform to a Torch tensor and prepare it for model input\n",
    "    waveform = torch.tensor(signal, dtype=torch.float32).unsqueeze(0)\n",
    "    \n",
    "    # Generate embeddings using the loaded classifier model\n",
    "    embeddings = classifier.encode_batch(waveform)\n",
    "    x = embeddings.numpy()  # Convert embeddings to NumPy array\n",
    "        \n",
    "    # Save embeddings to a file using the audio file ID as the filename\n",
    "    with open(path_save + id_audio + '.npy', 'wb') as f:\n",
    "        np.save(f, x)\n",
    "\n",
    "toc = time.time()  # End timing\n",
    "print('Duration:', round((toc - tic) / 60, 2), 'min')  # Print the total duration of processing in minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2fb4e6",
   "metadata": {},
   "source": [
    "## 1.2 RAVDESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1876da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os  # For interacting with the file system\n",
    "import time  # For measuring time intervals\n",
    "import librosa  # For audio processing\n",
    "import numpy as np  # For numerical operations\n",
    "import torch  # For tensor computations\n",
    "# import torchaudio  # For audio loading \n",
    "from speechbrain.pretrained import EncoderClassifier  # Import EncoderClassifier from SpeechBrain pretrained models\n",
    "\n",
    "# Load pretrained model\n",
    "classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-xvect-voxceleb\", \n",
    "                                                savedir= \"C:/Users/lugoza/Documents/AnacondaFiles/HELIOS_final/data/RAVDESS/embeddings/speechbrain-x-vector/models/\")    \n",
    "\n",
    "# Calculate embeddings per audio file\n",
    "path = 'C:/Users/lugoza/Documents/AnacondaFiles/HELIOS_final/data/RAVDESS/audios' # Path to audio files\n",
    "path_save = 'data/RAVDESS/embeddings/speechbrain-x-vector/audio_embeddings/' # Path to save embeddings\n",
    "\n",
    "tic = time.time() # Start timing\n",
    "\n",
    "# Iterate through each audio file in the specified path\n",
    "for folder in os.listdir(path):\n",
    "    for audio in os.listdir(path+'/'+folder+'/'):\n",
    "        id_audio = audio.split('.')[0] # Extract the audio file ID\n",
    "        \n",
    "        # Load audio using librosa due to potential issues with torchaudio's ogg file support\n",
    "        signal, fs = librosa.load(path+'/'+folder+'/'+audio, sr=16000, mono=True)\n",
    "        \n",
    "        # Convert the audio waveform to a Torch tensor and prepare it for model input\n",
    "        waveform = torch.tensor(signal, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        # Generate embeddings using the loaded classifier model\n",
    "        embeddings = classifier.encode_batch(waveform)\n",
    "        x = embeddings.numpy() # Convert embeddings to NumPy array\n",
    "\n",
    "        # Save embeddings to a file using the audio file ID as the filename\n",
    "        with open(path_save+id_audio+'.npy', 'wb') as f:\n",
    "            np.save(f, x)\n",
    "\n",
    "toc = time.time() # End timing\n",
    "print('Duration:',round((toc-tic)/60,2),'min') # Print the total duration of processing in minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5a3d7e",
   "metadata": {},
   "source": [
    "## 1.3 IEMOCAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a212cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os  # For interacting with the file system\n",
    "import time  # For measuring time intervals\n",
    "import librosa  # For audio processing\n",
    "import numpy as np  # For numerical operations\n",
    "import torch  # For tensor computations\n",
    "# import torchaudio  # For audio loading \n",
    "from speechbrain.pretrained import EncoderClassifier  # Import EncoderClassifier from SpeechBrain pretrained models\n",
    "\n",
    "# Load pretrained model\n",
    "classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-xvect-voxceleb\", \n",
    "                                            savedir= \"C:/Users/lugoza/Documents/AnacondaFiles/HELIOS_final/data/IEMOCAP/embeddings/speechbrain-x-vector/models/\")    \n",
    "\n",
    "# Calculate embeddings per audio file\n",
    "path = 'D:/lugoza/IEMOCAP/' # Path to audio files\n",
    "path_save = 'data/IEMOCAP/embeddings/speechbrain-x-vector/audio_embeddings/' # Path to save embeddings\n",
    "\n",
    "tic = time.time() # Start timing\n",
    "\n",
    "# Iterate through each audio file in the specified path\n",
    "for session in [folder for folder in os.listdir(path) if folder.startswith('Session')]:\n",
    "    for improv in os.listdir(path + session +'/sentences/wav/'):\n",
    "        for file in [f for f in os.listdir(path + session +'/sentences/wav/'+improv+'/') if f.endswith('.wav')]:\n",
    "            path_file = path + session +'/sentences/wav/'+improv+'/'+file    \n",
    "            id_audio = file.split('.')[0] # Extract the audio file ID\n",
    "            \n",
    "            # Load audio using librosa due to potential issues with torchaudio's ogg file support\n",
    "            signal, fs = librosa.load(path_file, sr=16000, mono=True)\n",
    "            \n",
    "            # Convert the audio waveform to a Torch tensor and prepare it for model input\n",
    "            waveform = torch.tensor(signal, dtype=torch.float32).unsqueeze(0)\n",
    "            \n",
    "            # Generate embeddings using the loaded classifier model\n",
    "            embeddings = classifier.encode_batch(waveform)\n",
    "            x = embeddings.numpy() # Convert embeddings to NumPy array\n",
    "\n",
    "            # Save embeddings to a file using the audio file ID as the filename\n",
    "            with open(path_save+id_audio+'.npy', 'wb') as f:\n",
    "                np.save(f, x)\n",
    "\n",
    "toc = time.time() # End timing\n",
    "print('Duration:',round((toc-tic)/60,2),'min') # Print the total duration of processing in minutes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
